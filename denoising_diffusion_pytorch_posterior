import math
import copy
from pathlib import Path
from random import random
from functools import partial
from collections import namedtuple
from multiprocessing import cpu_count

import torch
from torch import nn, einsum
import torch.nn.functional as F
from torch.nn import Module, ModuleList
from torch.cuda.amp import autocast
from torch.utils.data import Dataset, DataLoader

from torch.optim import Adam

from torchvision import transforms as T, utils

from einops import rearrange, reduce, repeat
from einops.layers.torch import Rearrange

from PIL import Image
from tqdm.auto import tqdm
from ema_pytorch import EMA

from accelerate import Accelerator
from MapTools import TorchMapTools

from attend import Attend

from version import __version__

    @torch.inference_mode()
    def ddim_sample(self, shape, return_all_timesteps = False):
        batch, device, total_timesteps, sampling_timesteps, eta, objective = shape[0], self.device, self.num_timesteps, self.sampling_timesteps, self.ddim_sampling_eta, self.objective
        
        times = torch.linspace(-1, total_timesteps - 1, steps = sampling_timesteps + 1)   # [-1, 0, 1, 2, ..., T-1] when sampling_timesteps == total_timesteps
        times = list(reversed(times.int().tolist()))
        time_pairs = list(zip(times[:-1], times[1:])) # [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]

        img = torch.randn(shape, device = device)
        imgs = [img]
        print(eta)
        x_start = None

        for time, time_next in tqdm(time_pairs, desc = 'sampling loop time step'):
            time_cond = torch.full((batch,), time, device = device, dtype = torch.long)
            self_cond = x_start if self.self_condition else None
            pred_noise, x_start, *_ = self.model_predictions(img, time_cond, self_cond, clip_x_start = True, rederive_pred_noise = True)

            if time_next < 0:
                img = x_start
                imgs.append(img)
                continue

            alpha = self.alphas_cumprod[time]
            alpha_next = self.alphas_cumprod[time_next]

            sigma = eta * ((1 - alpha / alpha_next) * (1 - alpha_next) / (1 - alpha)).sqrt()
            c = (1 - alpha_next - sigma ** 2).sqrt()

            noise = torch.randn_like(img)

            img = x_start * alpha_next.sqrt() + \
                  c * pred_noise + \
                  sigma * noise

            imgs.append(img)

        ret = img if not return_all_timesteps else torch.stack(imgs, dim = 1)

        ret = self.unnormalize(ret)
        return ret

    @torch.inference_mode()
    def sample(self, batch_size = 16, return_all_timesteps = False):
        (h, w), channels = self.image_size, self.channels
        print(self.is_ddim_sampling)
        sample_fn = self.p_sample_loop if not self.is_ddim_sampling else self.ddim_sample
        print('IS DDIM Sampling', self.is_ddim_sampling)
        return sample_fn((batch_size, channels, h, w), return_all_timesteps = return_all_timesteps)

    def unnorm_kappa(self, kappa, kappa_min = -0.08201675, kappa_max = 0.7101586):
        kappa_min =  -0.069016054
        kappa_max =  0.32133844
        kappa_unnorm = (kappa * (kappa_max - kappa_min)) + kappa_min
        #return kappa
        return kappa_unnorm

    def torch_kappa_to_shear(self, kappa, N_grid = 256, theta_max = 12., J = 1j, EPS = 1e-20): 
        torch_map_tool  = TorchMapTools(N_grid, theta_max)
        kappa_fourier = torch_map_tool.map2fourier(kappa)
        y_1, y_2   = torch_map_tool.do_fwd_KS(kappa_fourier)
        shear_map = torch.stack((y_1, y_2))
        return shear_map

    def compute_grad_log_lkl(self, x_t, x_start, noisy_image, sigma_noise): 
        #kappa_map = self.unnorm_kappa(x_start)
        kappa_map = x_start
        shears = torch.zeros_like(noisy_image)
        len, *_ = x_start.shape
        for i in range(len):
            shears[i] = (self.torch_kappa_to_shear(kappa_map[i].squeeze(0))).unsqueeze(0)
        loglkl = self.compute_complex_log_likelihood(shears, noisy_image, sigma_noise)
        loglkl.backward(retain_graph = True)
        grad_log_lkl = x_t.grad
        diff = shears - noisy_image
        norm = torch.norm(diff, p='fro')
        return grad_log_lkl, norm 

    def compute_complex_log_likelihood(self, noisy_pred, noisy_shear_map, sigma_noise):
        # Extract real and imaginary parts
        y_1 = noisy_pred[0][0]
        y_2 = noisy_pred[0][1]

        y_1_sim = noisy_shear_map[0][0]
        y_2_sim = noisy_shear_map[0][1]

        # Compute MSE for real and imaginary parts separately
        real_mse = -0.5 * (y_1 - y_1_sim)**2 / (sigma_noise**2)
        imag_mse = -0.5 * (y_2 - y_2_sim)**2 / (sigma_noise**2)

        # Sum the MSEs for real and imaginary parts to get a real-valued loss
        mse = real_mse + imag_mse
        return (-mse.sum())
        

    def ddim_sample_posterior(self, shape, noisy_image, sigma_noise, return_all_timesteps = False, zeta = .5):
        print("DDIM Sample Posterior called")
        batch, device, total_timesteps, sampling_timesteps, eta, objective = shape[0], self.device, self.num_timesteps, self.sampling_timesteps, self.ddim_sampling_eta, self.objective
        #zeta = 25.6510
        print('Zeta: ', zeta)
        times = torch.linspace(-1, total_timesteps - 1, steps = sampling_timesteps + 1)   # [-1, 0, 1, 2, ..., T-1] when sampling_timesteps == total_timesteps
        times = list(reversed(times.int().tolist()))
        time_pairs = list(zip(times[:-1], times[1:])) # [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]

        x_t = torch.randn(shape, device = device)
        imgs = [x_t]
        x_start = torch.zeros(shape, device = device)
        
        for time, time_next in tqdm(time_pairs, desc = 'sampling loop time step'):
            x_t.requires_grad = True
            time_cond = torch.full((batch,), time, device = device, dtype = torch.long)
            self_cond = x_start if self.self_condition else None
            pred_noise, x_start, *_ = self.model_predictions(x_t, time_cond, self_cond, clip_x_start = True, rederive_pred_noise = True)

            if time_next < 0:
                img = x_start
                imgs.append(img)
                continue

            alpha = self.alphas_cumprod[time]
            alpha_next = self.alphas_cumprod[time_next]

            sigma = eta * ((1 - alpha / alpha_next) * (1 - alpha_next) / (1 - alpha)).sqrt()
            c = (1 - alpha_next - sigma ** 2).sqrt()

            alpha_t = alpha/alpha_next
            noise = torch.randn_like(x_t)
            print('Timestep', time)
            print('beta_t: ', 1 - alpha_t)
            grad_log_lkl, norm = self.compute_grad_log_lkl(x_t, x_start, noisy_image, sigma_noise)
            print('Grad log likelihood: ', grad_log_lkl)
            print('Norm: ', norm)
            if(time > 0):
                with torch.no_grad():
                    x_t = (x_start * alpha_next.sqrt() + c * pred_noise + sigma * noise)
                    zeta_new = zeta/norm
                    x_t -= (1 - alpha_t) * (grad_log_lkl).detach()
                    #x_t -= zeta_new * (grad_log_lkl).detach()
            else: 
                with torch.no_grad():
                    x_t = (x_start * alpha_next.sqrt() + c * pred_noise + sigma * noise)

        ret = x_t if not return_all_timesteps else torch.stack(imgs, dim = 1)

        ret = self.unnormalize(ret)
        return ret

    def sample_posterior(self, batch_size = 16, return_all_timesteps = False, zeta = .5):
        print("Sample Posterior called")
        (h, w), channels = self.image_size, self.channels
        sample_fn = self.p_sample_loop if not self.is_ddim_sampling else self.ddim_sample_posterior
        return sample_fn((batch_size, channels, h, w), self.noisy_image, self.sigma_noise, return_all_timesteps = return_all_timesteps, zeta = zeta)

